---
title: "ML_Proj8 - Final"
author: "Austin Marckx"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(GGally)
library(ggpubr)
library(readxl)
library(randomForest)
library(caret)
library(cowplot)
library(tidyverse)
library(ggridges)

minmax <- function(x){
  return( (x - min(x))/(max(x) - min(x))  )
}

set.seed(3141526)
```


# Basic Preprocessing

- Read in data
- Ensure correct column types
- Check for missing data


```{r}
# Read in file
df <- read_xlsx('./data/AD.training.xlsx')

# Transform datatypes
df <- df %>% transform(
  PTID = factor(PTID),
  DX = factor(DX.bl, levels = c("CN", "EMCI", "LMCI", "AD")),
  PTGENDER = factor(PTGENDER),
  APOE4 = factor(APOE4)
) %>% select(AGE, PTEDUCAT, MMSE, PTGENDER, APOE4, DX, everything(), -DX.bl)

# Summary
df %>% head()
df %>% str()
df %>% summary()

any(is.na(df))
df[!complete.cases(df),]

```

There do not appear to be any missing values. Moreover each patient appears to be only represented once in the dataset (as the number of unique patient ids == number of rows.)


### Pair plot

- Looking for highly skewed variables
- Features which are collinear/linear transforms of one another/highly redundant
- Diversity sampling issues

```{r, fig.width= 18, fig.height=18, message = FALSE, warning = FALSE}
df %>% 
  mutate(asinsqrtMMSE = asin(sqrt(minmax(MMSE)))  ) %>%
  select(AGE, PTEDUCAT, MMSE, asinsqrtMMSE, everything(), MMSE.Change, -RID, -PTID, -EXAMDATE) %>% # removing factors with too many levels or irrelevant features
  ggpairs(aes(fill = PTGENDER, alpha = 0.7), progress = FALSE)

```
#
```{r}
# https://www.datanovia.com/en/blog/elegant-visualization-of-density-distribution-in-r-using-ridgeline/
df %>%
  ggplot(aes(x = `MMSE.Change`, y = DX, group = DX, fill = factor(stat(quantile)))) + 
  stat_density_ridges(
    geom = "density_ridges_gradient",
    calc_ecdf = TRUE,
    quantiles = 4,
    quantile_lines = TRUE, 
    jittered_points = TRUE,
    scale = 0.9,
    position = position_points_jitter(width = 0.05, height = 0.1),
    point_size = 1, point_alpha = 0.5, alpha = 0.7) + 
  theme_minimal() +
  scale_fill_brewer(name = 'Quartiles')
```

```{r, fig.width= 18, fig.height=18, message = FALSE, warning = FALSE}
df %>% 
  mutate(asinsqrtMMSE = asin(sqrt(minmax(MMSE)))  ) %>%
  select(AGE, PTEDUCAT, MMSE, asinsqrtMMSE, everything(), MMSE.Change, -RID, -PTID, -EXAMDATE) %>% # removing factors with too many levels or irrelevant features
  ggpairs(aes(fill = DX, alpha = 0.7), progress = FALSE)

```


salmon - CN
green - EMCI (Early mild cognitive impairment)
blue - LMCI (Late mild cognitive impairment)
purple - AD

# Remove non predictive features
```{r}
# Subset to only useful features
df_clean <- df %>% select(-RID, -PTID, -EXAMDATE)

```

# GLM Regression

## gaussian
```{r}
gauss <- glm(`MMSE.Change` ~ ., data = df_clean, family = gaussian())
summary(gauss)

plot(gauss)
``

# Random Forest Regression: 
```{r}
rf <- randomForest(`MMSE.Change` ~ ., data = df_clean, ntrees = 500, importance = TRUE, type = 'regression')
y_pred <- predict(rf)

rf
plot(rf)
importance(rf)
varImpPlot(rf)
```






```{r}
sessionInfo()
```



