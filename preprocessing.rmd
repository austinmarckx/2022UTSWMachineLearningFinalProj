---
title: "ML_Proj8 - Final"
author: "Austin Marckx"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(GGally)
library(ggpubr)
library(readxl)
library(randomForest)
library(caret)
library(cowplot)
library(tidyverse)
library(ggridges)
library(boot)
library(mclust)
library("FactoMineR")
library("factoextra")

minmax <- function(x){
  return( (x - min(x))/(max(x) - min(x))  )
}

set.seed(3141526)
```


# Basic Preprocessing

- Read in data
- Ensure correct column types
- Check for missing data


```{r}
# Read in file
df <- read_xlsx('./data/AD.training.xlsx')

# Transform datatypes
df <- df %>% transform(
  PTID = factor(PTID),
  DX = factor(DX.bl, levels = c("CN", "EMCI", "LMCI", "AD")),
  PTGENDER = factor(PTGENDER),
  APOE4 = factor(APOE4)
) %>% select(AGE, PTEDUCAT, MMSE, PTGENDER, APOE4, DX, everything(), -DX.bl)

# Summary
df %>% head()
df %>% str()
df %>% summary()

any(is.na(df))
df[!complete.cases(df),]

```

There do not appear to be any missing values. Moreover each patient appears to be only represented once in the dataset (as the number of unique patient ids == number of rows.)


### Pair plot

- Looking for highly skewed variables
- Features which are collinear/linear transforms of one another/highly redundant
- Diversity sampling issues

```{r, fig.width= 18, fig.height=18, message = FALSE, warning = FALSE}
df %>% 
  mutate(asinsqrtMMSE = asin(sqrt(minmax(MMSE)))  ) %>%
  select(AGE, PTEDUCAT, MMSE, asinsqrtMMSE, everything(), MMSE.Change, -RID, -PTID, -EXAMDATE) %>% # removing factors with too many levels or irrelevant features
  ggpairs(aes(fill = PTGENDER, alpha = 0.7), progress = FALSE)

```
#
```{r}
# https://www.datanovia.com/en/blog/elegant-visualization-of-density-distribution-in-r-using-ridgeline/
df %>%
  ggplot(aes(x = `MMSE.Change`, y = DX, group = DX, fill = factor(stat(quantile)))) + 
  stat_density_ridges(
    geom = "density_ridges_gradient",
    calc_ecdf = TRUE,
    quantiles = 4,
    quantile_lines = TRUE, 
    jittered_points = TRUE,
    scale = 0.9,
    position = position_points_jitter(width = 0.05, height = 0.1),
    point_size = 1, point_alpha = 0.5, alpha = 0.7) + 
  theme_minimal() +
  scale_fill_brewer(name = 'Quartiles')
```

```{r, fig.width= 18, fig.height=18, message = FALSE, warning = FALSE}
df %>% 
  mutate(asinsqrtMMSE = asin(sqrt(minmax(MMSE)))  ) %>%
  select(AGE, PTEDUCAT, MMSE, asinsqrtMMSE, everything(), MMSE.Change, -RID, -PTID, -EXAMDATE) %>% # removing factors with too many levels or irrelevant features
  ggpairs(aes(fill = DX, alpha = 0.7), progress = FALSE)

```

#
```{r}
# https://www.datanovia.com/en/blog/elegant-visualization-of-density-distribution-in-r-using-ridgeline/
df %>%
  select(PTID, `MMSE.Change`, MMSE, DX) %>%
  mutate(MMSE4mo = MMSE + `MMSE.Change`) %>%
  select(-`MMSE.Change`) %>%
  pivot_longer(cols = c(MMSE4mo, MMSE),  names_to = 'time', values_to = 'MMSE') %>%
  ggplot(aes(x = MMSE, y = time, group = time, fill = factor(stat(quantile)))) + 
  stat_density_ridges(
    geom = "density_ridges_gradient",
    calc_ecdf = TRUE,
    quantiles = 4,
    quantile_lines = TRUE, 
    jittered_points = TRUE,
    scale = 0.9,
    position = position_points_jitter(width = 0.05, height = 0.1),
    point_size = 1, point_alpha = 0.5, alpha = 0.7) + 
  theme_minimal() +
  scale_fill_brewer(name = 'Quartiles')
```

#
```{r}
# https://www.datanovia.com/en/blog/elegant-visualization-of-density-distribution-in-r-using-ridgeline/
df %>%
  select(PTID, `MMSE.Change`, MMSE, DX) %>%
  mutate(MMSE4mo = MMSE + `MMSE.Change`) %>%
  select(-`MMSE.Change`) %>%
  pivot_longer(cols = c(MMSE4mo, MMSE),  names_to = 'time', values_to = 'MMSE') %>%
  ggplot(aes(x = MMSE, y = time, group = PTID, color = DX)) + 
    geom_jitter(width = 0.2, height = 0.075) +
    geom_line() +
    geom_violin(aes(color = NULL, fill = time, group = time), alpha = 0.15, draw_quantiles = c(0.25, 0.5, 0.75)) + 
  theme_minimal() +
  facet_wrap(~DX)
```

# Look at Summary stats
```{r}

# By Time
df %>% 
  select(PTID, `MMSE.Change`, MMSE, DX) %>%
  mutate(MMSE4mo = MMSE + `MMSE.Change`) %>%
  select(-`MMSE.Change`) %>%
  pivot_longer(cols = c(MMSE4mo,MMSE),  names_to = 'time', values_to = 'MMSE') %>%
  group_by(time) %>% rstatix::get_summary_stats()

# By time and DX
df %>% 
  select(PTID, `MMSE.Change`, MMSE, DX) %>%
  mutate(MMSE4mo = MMSE + `MMSE.Change`) %>%
  select(-`MMSE.Change`) %>%
  pivot_longer(cols = c(MMSE4mo,MMSE),  names_to = 'time', values_to = 'MMSE') %>%
  group_by(DX, time) %>% rstatix::get_summary_stats()

```


salmon - CN
green - EMCI (Early mild cognitive impairment)
blue - LMCI (Late mild cognitive impairment)
purple - AD

# Remove non predictive features
```{r}
# Subset to only useful features
df_clean <- df %>% select(-RID, -PTID, -EXAMDATE)
df_clean %>% head()

# More subsets
X <- df_clean %>% select(-`MMSE.Change`)
df_numerical <- df_clean %>% select(-`MMSE.Change`, -PTGENDER, -APOE4, -DX)
df_categorical <- df_clean %>% select(-`MMSE.Change`, -AGE, -MMSE, -PTEDUCAT)
```

# GLM Regression

## gaussian
```{r}
gauss <- glm(`MMSE.Change` ~ ., data = df_clean, family = gaussian())
summary(gauss)
plot(gauss)
```


# Random Forest Regression: 
```{r}
rf <- randomForest(`MMSE.Change` ~ ., data = df_clean, ntrees = 500, importance = TRUE, type = 'regression')
y_pred <- predict(rf)

rf
plot(rf)
importance(rf)
varImpPlot(rf)
```

# Bootstrapping (!?): 
```{r}
#https://www.statmethods.net/advstats/bootstrapping.html
bs <- function(formula, data, indices) {
  d <- data[indices,] # allows boot to select sample
  fit <- glm(formula, data=d, family = gaussian())
  return(coef(fit))
}

results <- boot(data = df_clean, statistic=bs, formula = `MMSE.Change` ~ ., R = 1000)

results
plot(results)
plot(results, index = 10)

boot.ci(results, index = 10)
```





# Gaussian Mixture: 
```{r, fig.height = 12, fig.width=12}
gmm <- Mclust(df_numerical)
summary(gmm)
plot(gmm, what = "BIC")
plot(gmm, what = "classification")
```

# PCA 
```{r}
# http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/115-famd-factor-analysis-of-mixed-data-in-r-essentials/

resPCA <- PCA(df_numerical)

resPCA
fviz_screeplot(resPCA)
fviz_famd_var(resPCA, "quanti.var", col.var = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)

```


# FAMD
```{r}
# http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/115-famd-factor-analysis-of-mixed-data-in-r-essentials/

resFAMD <- FAMD(df_clean)

resFAMD
fviz_mfa_ind(resFAMD, 
             habillage = "MMSE.Change", # color by groups 
             #palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, ellipse.type = "confidence", 
             repel = TRUE # Avoid text overlapping
             ) 
```

# Gaussian Mixture: 
```{r, fig.height = 12, fig.width=12}
gmm <- Mclust(df_numerical)
summary(gmm)
plot(gmm, what = "BIC")
plot(gmm, what = "classification")
```

































```{r}
sessionInfo()
```



